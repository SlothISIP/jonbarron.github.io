<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>APEX-ML - AutoML Platform | Ju O Kim</title>

    <meta name="description" content="Enterprise GPU-Optimized AutoML Platform with 6 algorithm families (81 configurations), 3-phase pipeline for imbalanced classification.">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Ju O Kim">
    <link rel="canonical" href="https://slothisip.github.io/projects/apex-ml/">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://slothisip.github.io/projects/apex-ml/">
    <meta property="og:title" content="APEX-ML - Enterprise AutoML Platform">
    <meta property="og:description" content="GPU-accelerated AutoML with 6 algorithm families, 3-phase pipeline for manufacturing and fraud detection.">
    <meta property="og:image" content="https://slothisip.github.io/images/apex_ml_thumb.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:site_name" content="Ju O Kim - Portfolio">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:url" content="https://slothisip.github.io/projects/apex-ml/">
    <meta name="twitter:title" content="APEX-ML - Enterprise AutoML Platform">
    <meta name="twitter:description" content="GPU-accelerated AutoML with 6 algorithm families, 3-phase pipeline for manufacturing and fraud detection.">
    <meta name="twitter:image" content="https://slothisip.github.io/images/apex_ml_thumb.png">
    <meta name="twitter:image:alt" content="APEX-ML AutoML platform architecture diagram">

    <link rel="shortcut icon" href="../../images/favicon/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                APEX-ML: Enterprise AutoML Platform
                <small>
                    6 Algorithm Families | 3-Phase Pipeline | GPU-Accelerated
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="../../index.html">
                          Ju O Kim
                        </a>
                        </br>Keimyung University
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Overview
                </h3>
                <p class="text-justify">
                    APEX-ML is an enterprise-grade AutoML platform featuring 6 algorithm families across a sophisticated 3-phase pipeline: Rapid Screening, Bayesian Optimization, and Ensemble Construction. Reduces model development time by 80%+ (weeks to days) with 60-80% GPU utilization through distributed computing via Ray clusters, enabling non-ML engineers to build production-ready models.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    System Architecture
                </h3>
                <center>
                    <img src="images/architecture.svg" class="img-responsive" alt="System Architecture" style="max-width: 100%; background: #1a0a2e; border-radius: 8px; padding: 10px;">
                </center>
                <br>
                <p class="text-justify">
                    The 3-phase AutoML pipeline architecture: Phase 1 rapidly screens 81 algorithms in parallel, Phase 2 performs Bayesian optimization with Optuna for hyperparameter tuning, and Phase 3 constructs optimized ensembles through model stacking. GPU acceleration via Ray cluster enables 60-80% utilization on RTX 4090.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Algorithm Composition (81 Total)
                </h3>
                <p class="text-justify">
                    APEX-ML integrates <strong>81 machine learning algorithms</strong> across 6 specialized categories for comprehensive algorithm space exploration:
                </p>
                <table class="table table-striped">
                    <thead>
                        <tr style="background-color: #f5f5f5;">
                            <th>Algorithm Family</th>
                            <th style="text-align: center;">Count</th>
                            <th>Key Algorithms</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Tree-Based</strong></td>
                            <td style="text-align: center;"><strong>18</strong></td>
                            <td>XGBoost, LightGBM, CatBoost, Random Forest, Gradient Boosting</td>
                        </tr>
                        <tr>
                            <td><strong>Neural Networks</strong></td>
                            <td style="text-align: center;"><strong>22</strong></td>
                            <td>PyTorch DNNs (1-4 layers), LSTM, GRU, Residual Networks</td>
                        </tr>
                        <tr>
                            <td><strong>Deep Tabular</strong></td>
                            <td style="text-align: center;"><strong>14</strong></td>
                            <td>TabNet, NODE, SAINT, FT-Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>Classical ML</strong></td>
                            <td style="text-align: center;"><strong>16</strong></td>
                            <td>SVM, Ridge/Lasso, Elastic Net, KNN, Logistic Regression</td>
                        </tr>
                        <tr>
                            <td><strong>Ensemble Methods</strong></td>
                            <td style="text-align: center;"><strong>8</strong></td>
                            <td>Voting, Bagging, Boosting, Stacking (adaptive weights)</td>
                        </tr>
                        <tr>
                            <td><strong>Meta-Learning</strong></td>
                            <td style="text-align: center;"><strong>3</strong></td>
                            <td>Warm-start configs, Transfer learning initializations</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Key Differentiators
                </h3>
                <p class="text-justify">
                    APEX-ML is designed specifically for <strong>manufacturing and fraud detection</strong> use cases with GPU-native architecture:
                </p>
                <table class="table table-bordered" style="font-size: 0.9em;">
                    <thead>
                        <tr style="background-color: #e8f4f8;">
                            <th>Feature</th>
                            <th style="text-align: center;">APEX-ML</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Algorithm Count</td>
                            <td style="text-align: center;"><strong>81</strong> curated algorithms</td>
                        </tr>
                        <tr>
                            <td>GPU Acceleration</td>
                            <td style="text-align: center;"><strong>Full CUDA</strong> pipeline</td>
                        </tr>
                        <tr>
                            <td>Parallel Screening</td>
                            <td style="text-align: center;"><strong>All 81</strong> algorithms simultaneously</td>
                        </tr>
                        <tr>
                            <td>End-to-End Runtime</td>
                            <td style="text-align: center;"><strong>10-25 min</strong> on RTX 4090</td>
                        </tr>
                        <tr>
                            <td>Target Domain</td>
                            <td style="text-align: center;">Imbalanced classification, fraud detection</td>
                        </tr>
                    </tbody>
                </table>
                <p class="text-center" style="font-size: 0.85em; color: #666; margin-top: 10px;">
                    <em>Note: Code available upon request for academic collaboration.</em>
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    3-Phase Dashboard Overview
                </h3>
                <center>
                    <img src="images/APEX_1.png" class="img-responsive" alt="3-Phase Dashboard Overview">
                </center>
                <br>
                <p class="text-justify">
                    The main dashboard provides a comprehensive view of the entire AutoML pipeline, displaying real-time status of all three phases. Phase 1 rapidly screens all 81 algorithms in parallel, Phase 2 performs Bayesian hyperparameter optimization on top candidates using Optuna, and Phase 3 constructs evolutionary ensembles through model stacking.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Bayesian Optimization Visualization
                </h3>
                <center>
                    <img src="images/APEX_2.png" class="img-responsive" alt="Bayesian Optimization Visualization">
                </center>
                <br>
                <p class="text-justify">
                    Phase 2 employs Optuna-based Bayesian optimization for hyperparameter tuning. This visualization shows the optimization landscape, acquisition function, and convergence trajectory as the system explores the hyperparameter space to find optimal configurations for top-performing algorithms.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Ensemble Performance Metrics
                </h3>
                <center>
                    <img src="images/APEX_3.png" class="img-responsive" alt="Ensemble Performance Metrics">
                </center>
                <br>
                <p class="text-justify">
                    The ensemble performance dashboard displays comparative metrics across individual models and their combined ensemble predictions. Charts show accuracy, F1 score, precision, and recall improvements achieved through model stacking and dynamic weighting strategies in Phase 3.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Feature Importance Matrix
                </h3>
                <center>
                    <img src="images/APEX_4.png" class="img-responsive" alt="Feature Importance Matrix">
                </center>
                <br>
                <p class="text-justify">
                    The feature importance matrix provides interpretability insights by aggregating feature rankings across multiple algorithms. This cross-model analysis reveals which input features consistently drive predictions, supporting feature selection and model explainability requirements.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Phase 1 Rapid Screening
                </h3>
                <center>
                    <img src="images/APEX_5.png" class="img-responsive" alt="Phase 1 Rapid Screening">
                </center>
                <br>
                <p class="text-justify">
                    The rapid screening interface shows parallel evaluation of all 81 algorithms during Phase 1. GPU-accelerated processing enables simultaneous model training with real-time progress tracking, algorithm success/failure status, and preliminary performance rankings.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Technical Specifications
                </h3>
                <table class="table table-bordered">
                    <tbody>
                        <tr style="background-color: #e8f4f8;">
                            <td><strong>Total Algorithms</strong></td>
                            <td><strong>81</strong> curated: 18 Tree + 22 Neural + 14 Deep Tabular + 16 Classical + 8 Ensemble + 3 Meta</td>
                        </tr>
                        <tr>
                            <td><strong>Target Domain</strong></td>
                            <td>Imbalanced classification, manufacturing defect detection, fraud detection</td>
                        </tr>
                        <tr>
                            <td><strong>GPU Utilization</strong></td>
                            <td>60-80% (RTX 4090) - Full CUDA pipeline from preprocessing to inference</td>
                        </tr>
                        <tr>
                            <td><strong>End-to-End Runtime</strong></td>
                            <td>10-25 min (Phase 1: 2-5 min | Phase 2: 5-15 min | Phase 3: 2-5 min)</td>
                        </tr>
                        <tr>
                            <td><strong>Hyperparameter Opt.</strong></td>
                            <td>Optuna with Tree-structured Parzen Estimator (TPE)</td>
                        </tr>
                        <tr>
                            <td><strong>Core Stack</strong></td>
                            <td>Python 3.10+, PyTorch 2.0, scikit-learn, XGBoost, LightGBM</td>
                        </tr>
                        <tr>
                            <td><strong>Distributed</strong></td>
                            <td>Ray cluster with fault tolerance, multi-node scaling (1â†’10+ GPUs)</td>
                        </tr>
                        <tr>
                            <td><strong>API</strong></td>
                            <td>FastAPI (port 8010) with sub-100ms inference latency</td>
                        </tr>
                        <tr style="background-color: #fff3cd;">
                            <td><strong>Specialization</strong></td>
                            <td>Fraud detection + imbalanced classification (vs. general-purpose AutoML)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

    </div>
</body>
</html>
